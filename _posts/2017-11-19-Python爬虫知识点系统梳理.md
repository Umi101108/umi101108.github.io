---
layout: post
title:  "Python爬虫知识点系统梳理"
date:   2017-11-19
categories: Python
tags: Python 爬虫 
excerpt: Python爬虫知识点系统梳理
---
* content
{:toc}


# 爬虫知识点

玩转爬虫需要点亮的技能树

## 1. 确定目标

此阶段首先需要确定所使用的爬虫框架，对于一般结构简单的网页也可以直接用requests包请求，复杂的就需要使用功能强大的爬虫框架来助力开发

### 爬虫框架

* Scrapy - 网络爬虫框架（基于twisted）
* grab - 网络爬虫框架（基于pycurl/multicur）
* pyspider - 一个强大的爬虫系统
* cola - 一个分布式爬虫框架
* porita - 基于Scrapy的可视化爬虫
* restkit - Python的HTTP资源工具包，它可以让你轻松的访问HTTP资源，并围绕它建立的对象
* demiurge - 基于PyQuery的爬虫微框架
  ​



## 2. 发起请求

此阶段主要是请求数据包，返回数据，可以说是最重要的环节

### 解析请求

* Chrome - 最基本的网页解析
* Fiddler - 抓包工具
* Charles - 抓包工具
* Postman

### 请求相关的包

* urllib - 网络库
* requests - 网络库
* grab - 网络库（基于pycurl）
* pycurl - 网络库（绑定libcurl）
* urllib3 - Python HTTP库，安全连接池、支持文件post、可用性高
* httplib2 - 网络库
* RoboBrower - 一个简单的，无需独立的浏览器即可浏览网页
* MechanicalSoup - 一个与网页自动交互的Python库
* mechanize - 有状态、可编程的Web浏览库
* socket - 底层网络结构（stdlib）
* Unirest for Python - Unirest是可用于多种语言的轻量级HTTP库
* hpyer - Python的HTTP2客户端
* PySocks - 作为socket模块的直接替换
* treq - 类似于requests的API（基于twisted）
* aiohttp - asyncio的HTTP客户端/服务器（PEP-3156)

### 浏览器自动化与仿真

* selenium - 自动化真正的浏览器（Chrome、Firefox、Opera、IE）
* Ghost.py - 对PyQt的webkit的封装（需要PyQT）
* Spynner - 对PyQt的webkit的封装（需要PyQT）
* Splinter - 通用API浏览器模拟器（selenium web驱动，Django客户端，Zope）
* phantomjs - 无界面浏览器

### 网址URL操作

* furl - 一个小的Python库，使得操纵URL简单化
* purl - 一个简单的不可改变的URL以及一个干净的用于调试和操作的API
* urllib.parse - 用于打破统一资源定位器（URL)的字符串在组件（寻址方案、网络位置、路径等）之间的隔断，为了组合组件到一个URL字符串，并将“相对URL”转化为一个绝对URL，称之为”基本URL“
* tldextract - 从URL的注册域和子域中准确分离TLD，使用公共后缀列表
* netaddr - 用于显示和操纵网络地址的Python库

### 多线程进程

#### 异步

* asyncio - 异步I/O，时间循环，协同程序和任务
* Twisted - 基于事件驱动的网络引擎框架
* Tornado - 一个网络框架和异步网络库
* pulsar - Python事件驱动的并发框架
* diesel - Python的基于绿色事件的I/O框架
* gevent - 一个使用greenlet的基于协程的Python网络库
* eventlet - 一个WSGI支持的异步框架
* Tomorrow - 异步代码的奇妙的修饰语法

#### 队列

* celery - 基于分布式消息传递的异步任务队列/作业队列

* huey - 小型多线程任务队列

* mrq-Mr.Queue - 使用redis&Gevent的Python分布式工作任务队列

* RQ - 基于Redis的轻量级任务队列管理器

* simpleq - 一个简单的、可无限扩展，基于Amazon SQS的队列

* python-gearman - Gearman的Python API

* redis - 基于内存的数据库，高速高效





## 3. 解析数据

得到响应数据之后就是提取所需数据的环节了，这个阶段方法众多，掌握常用的几种触类旁通即可。

### HTML/XML解析器

* lxml - C语言编写的高效HTML/XML处理器，支持XPath
* cssselect - 解析DOM树和CSS选择器
* pyquery - 解析DOM树和jQuery选择器
* BeautifulSoup - 低效HTML/XML处理库，纯Python实现
* html5lib - 根据WHATWG规范生成HTML/XML文档的DOM，该规范被用在现在所有的浏览器上
* feedparser - 解析RSS/ATOM feeds
* MarkupSafe - 为XML/HTML/XHTML提供了安全转义的字符串
* xmltodict - 一个可以让你在处理XML时感觉像在处理JSON一样的Python模块
* xhtml2pdf - 将HTML/CSS转换为PDF
* untangle - 轻松实现将XML文件转换为Python对象
* Bleach - 清理HTML（需要html5lib）
* sanitize - 为混乱的数据世界带来清明

### 网页内容提取

#### HTML页面的文本和元数据
* wget - 整站下载
* newspaper - 用Python进行新闻提取、文章提取和内容扩展
* html2text - 将HTML转为Markdown格式文本
* python-goose - HTML内容/文章提取器
* lassie - 人性化的网页内容检索工具
* micawber - 一个从网址中提取丰富内容的小库
* sumy - 一个自动汇总文本文件和HTML网页的模块
* Haul- 一个可扩展的图像爬虫
* python-readability - arc90 readability工具的快速Python接口
* scrapely - 从HTML网页中提取结构化数据的库。给出了一些Web页面和数据提取的示例，scrapely为所有类似的网页构建一个分析器
#### 视频
* youtube-dl - 一个从YouTube下载视频的小命令行程序
* you-get - Python3的YouTube、优酷/Niconico视频下载器
#### 维基
* WikiTeam - 下载和保存wikis的工具



### 文本处理

#### 通用

* difflib - 帮助进行差异化比较
* Levenshtein - 快速计算Levenshtein距离和字符串相似度
* fuzzywuzzy - 模糊字符串匹配
* esmre - 正则表达式加速器
* ftfy - 自动整理Unicode文本，减少碎片化

#### 字符编码

* unidecode - 将Unicode文本转为ASCII
* uniout - 打印可读字符，而不是被转义的字符串
* chardet - 兼容Python的2/3的字符编码器
* xpinyin - 一个将中国汉字转为拼音的库
* pangu.py - 格式化文本中CJK和字母数字的间距

#### Slug化

* awesome-slugify - 一个可以保留unicode的Python slugify库
* python-slugify - 一个可以将Unicode转为ASCII的Python slugify库
* unicode-slugify - 一个可以将生成的Unicode slugs的工具
* pytils - 处理俄语字符串的简单工具（包括pytils.translit.slugify)

#### 通用解析器

* PLY - lex和yacc解析工具的Python实现
* pyparsing - 一个通用框架的生成语法分析器

#### 人的名字

* python-nameparser - 解析人的名字的组件

#### 电话号码

* phonenumbers - 解析，格式化，存储和验证国际电话号码

#### 用户代理字符串

* python-user-agent - 浏览器用户代理的解析器
* HTTP Agent Parser - Python的HTTP代理分析器



### 自然语言处理

* NLTK - 编写Python程序来处理人类语言数据的最好平台
* Pattern - Python的网络挖掘模块，有自然语言处理工具，机器学习以及其他
* TextBlob - 为深入自然语言处理任务提供了一直的API，是基于NLTK以及Pattern的巨人肩膀上发展的
* jieba - 中文分词工具
* SnowNLP - 中文文本处理库
* loso - 另一个中文分词库
* genius - 基于条件随机域的中文分词
* langid.py - 独立的语言识别系统
* Korean - 一个韩文形态库
* pymorphy2 - 俄语形态分析器（词性标注+词形变化引擎）
* PyPLN - 用Python编写的分布式自然语言处理通道。这个项目的目标是创建一种简单的方法使用NLTK通过网络接口处理大语言库

### 计算机视觉解析

* OpenCV - 开源计算机视觉库
* SimpleCV - 用于照相机、图像处理、特征提取、格式转换的简介，可读性强的接口（基于OpenCV）
* mahotas - 快速计算机图像处理算法（完全使用C++实现），完全基于numpy的数据作为它的数据类型



### 特定格式文件处理

#### 通用

* table - 一个把数据导出为xls、csv、json、yaml等格式的模块
* textract - 从各种文件中提取文本，比如Word、PowerPoint、PDF等
* messytables - 解析混乱的表格数据的工具
* rows - 一个常用数据接口，支持的格式很多（目前支持CSV、HTML、XLS、TXT，将来还会提供更多）

#### Office

* python-docx - 读取、查询和修改的Microsoft Word2007/2008的docx文件
* xlwt/xlrd - 从Excel文件读取写入数据和格式信息
* XlsxWriter - 一个创建Excel.xlsx文件的Python模块
* xlwings - 一个BSD许可的库，可以很容易地在Excel中调用Python，反之亦然
* openpyxl - 一个用于读取和写入的Excel2010 XLSX/XLSM/XLTX/XLTM文件的库
* Marmir - 提取Python数据结构并将其转换为电子表格

#### PDF

* PDFMiner - 一个从PDF文档中提取信息的工具
* PyPDF2 - 一个能够分割、合并和转换PDF页面的库
* ReportLab - 允许快速创建丰富的PDF文档
* pdftables - 直接从PDF文件中提取表格

#### Markdown

* Python-Markdown - 一个用Python实现的John Gruber的Markdown
* Mistune - 速度最快，功能全面的Markdown纯Python解析器
* markdown2 - 一个完全用Python实现的快速的Markdown

#### YAML

* PyYAML - 一个Python的YAML解析器

#### CSS

* cssutils - 一个Python的CSS库


#### ATOM/RSS

* feedparser - 通用的feed解析器

#### SQL

* sqlparse - 一个非验证的SQL语句分析器

#### HTTP

* http-parser- C语言实现的HTTP请求/响应消息解析器

#### 微格式

* opengraph - 一个用来解析Open Graph协议标签的Python模块

#### 可移植的执行体

* pefile - 一个多平台的用于解析和处理可移植执行体（即PE）文件的模块

#### PSD

* psd-tools - 将Adobe Photoshop PSD（即PE）文件读取到Python数据结构



## 4. 存储入库

最后一步自然就是将提取的数据保存下来，简单的数据直接保存csv、txt即可，大量数据就需要保存到数据库中了

### SQL

* MySQL - 常用的数据库

### NoSQL

* MongoDB - 常用的非结构化数据库
* ElasticSearch - 提供强大的搜索功能
* Redis - 基于内存的数据库