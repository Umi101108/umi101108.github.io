---
layout: post
title:  "Python爬虫知识点系统梳理"
date:   2017-11-19
categories: Python
tags: Python 爬虫 
excerpt: Python爬虫知识点系统梳理
---
* content
{:toc}


# 爬虫知识点

玩转爬虫需要点亮的技能树

## 1. 确定目标

此阶段首先需要确定所使用的爬虫框架，对于一般结构简单的网页也可以直接用requests包请求，复杂的就需要使用功能强大的爬虫框架来助力开发

### 爬虫框架

* Scrapy - 网络爬虫框架（基于twisted）
* grab - 网络爬虫框架（基于pycurl/multicur）
* pyspider - 一个强大的爬虫系统
* cola - 一个分布式爬虫框架
* porita - 基于Scrapy的可视化爬虫
* restkit - Python的HTTP资源工具包，它可以让你轻松的访问HTTP资源，并围绕它建立的对象
* demiurge - 基于PyQuery的爬虫微框架
  ​



## 2. 发起请求

此阶段主要是请求数据包，返回数据，可以说是最重要的环节

### 解析请求

* Chrome - 最基本的网页解析
* Fiddler - 抓包工具
* Charles - 抓包工具
* Postman

### 请求相关的包

* urllib - 网络库
* requests - 网络库
* grab - 网络库（基于pycurl）
* pycurl - 网络库（绑定libcurl）
* urllib3 - Python HTTP库，安全连接池、支持文件post、可用性高
* httplib2 - 网络库
* RoboBrower - 一个简单的，无需独立的浏览器即可浏览网页
* MechanicalSoup - 一个与网页自动交互的Python库
* mechanize - 有状态、可编程的Web浏览库
* socket - 底层网络结构（stdlib）
* Unirest for Python - Unirest是可用于多种语言的轻量级HTTP库
* hpyer - Python的HTTP2客户端
* PySocks - 作为socket模块的直接替换
* treq - 类似于requests的API（基于twisted）
* aiohttp - asyncio的HTTP客户端/服务器（PEP-3156)

### 浏览器自动化与仿真

* selenium - 自动化真正的浏览器（Chrome、Firefox、Opera、IE）
* Ghost.py - 对PyQt的webkit的封装（需要PyQT）
* Spynner - 对PyQt的webkit的封装（需要PyQT）
* Splinter - 通用API浏览器模拟器（selenium web驱动，Django客户端，Zope）
* phantomjs - 无界面浏览器

### 多线程进程

#### 异步

* asyncio - 异步I/O，时间循环，协同程序和任务
* Twisted - 基于事件驱动的网络引擎框架
* Tornado - 一个网络框架和异步网络库
* pulsar - Python事件驱动的并发框架
* diesel - Python的基于绿色事件的I/O框架
* gevent - 一个使用greenlet的基于协程的Python网络库
* eventlet - 一个WSGI支持的异步框架
* Tomorrow - 异步代码的奇妙的修饰语法

#### 队列

* celery - 基于分布式消息传递的异步任务队列/作业队列

* huey - 小型多线程任务队列

* mrq-Mr.Queue - 使用redis&Gevent的Python分布式工作任务队列

* RQ - 基于Redis的轻量级任务队列管理器

* simpleq - 一个简单的、可无限扩展，基于Amazon SQS的队列

* python-gearman - Gearman的Python API

* redis - 基于内存的数据库，高速高效





## 3. 解析数据

得到响应数据之后就是提取所需数据的环节了，这个阶段方法众多，掌握常用的几种触类旁通即可。

